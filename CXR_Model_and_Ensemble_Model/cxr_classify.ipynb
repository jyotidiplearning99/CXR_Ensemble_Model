{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.losses import MSE\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, SeparableConv2D\n",
    "from keras.layers import Input, Add, Flatten, ReLU, Concatenate,ELU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:23:40.652972Z",
     "end_time": "2024-04-24T22:23:44.264132Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "# Set TensorFlow logging level to suppress warnings\n",
    "#tf.get_logger().setLevel(logging.ERROR)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:23:44.265637Z",
     "end_time": "2024-04-24T22:23:44.279134Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "def resize_with_ratio(image, dims, interpolationFlag):\n",
    "    height, width = image.shape\n",
    "    scale_factor = min(dims[0] / width, dims[1] / height)\n",
    "\n",
    "    target_original_height = int(height * scale_factor)\n",
    "    target_original_width = int(width * scale_factor)\n",
    "\n",
    "    if interpolationFlag == \"Spline\":\n",
    "        downscaled_image = zoom(image, scale_factor, order = 3)\n",
    "    else:\n",
    "        downscaled_image = cv2.resize(image, (target_original_width, target_original_height),\n",
    "                                      interpolation=interpolationFlag)\n",
    "\n",
    "    pad_top = (dims[1] - target_original_height) // 2\n",
    "    pad_bottom = dims[1] - target_original_height - pad_top\n",
    "    pad_left = (dims[0] - target_original_width) // 2\n",
    "    pad_right = dims[0] - target_original_width - pad_left\n",
    "\n",
    "    padded_image = cv2.copyMakeBorder(downscaled_image, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT)\n",
    "\n",
    "    return padded_image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:23:44.279134Z",
     "end_time": "2024-04-24T22:23:44.299135Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#clahe = cv2.createCLAHE(clipLimit = 2.5, tileGridSize = (4,4))\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "def load_data(directory, image_size=(250, 250)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, category in enumerate([\"NORMAL\", \"PNEUMONIA\"]):\n",
    "        category_path = os.path.join(directory, category)\n",
    "        for file_name in tqdm(os.listdir(category_path)):\n",
    "            image_path = os.path.join(category_path, file_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = resize_with_ratio(image, (600, 600), cv2.INTER_AREA)\n",
    "            #image = image / 255.0\n",
    "            #sigma = estimate_sigma(image, multichannel=False, average_sigmas=True)\n",
    "            #image = denoise_nl_means(image, patch_size=4,\n",
    "            #                         patch_distance=2,\n",
    "            #                         h=0.2 * sigma, fast_mode=True)\n",
    "            #image = (image*255).astype(\"uint8\")\n",
    "            #image = clahe.apply(image)\n",
    "            #image = cv2.resize(image, image_size, interpolation = cv2.INTER_AREA)\n",
    "            #image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "            image = image / 255.0\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            images.append(image)\n",
    "            if category == \"PNEUMONIA\":\n",
    "                labels.append(1)  # Assign label 1 for PNEUMONIA images\n",
    "            else:\n",
    "                labels.append(0)  # Assign label 0 for NORMAL images\n",
    "    return np.array(images), np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:23:44.299135Z",
     "end_time": "2024-04-24T22:23:44.311131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 2: Define the CNN architecture\n",
    "def residual_block(layer, k_, in_, out_, strides = (1,1), useShortcut = False):\n",
    "\n",
    "    shortcut = layer\n",
    "\n",
    "    layer = SeparableConv2D(in_, kernel_size=k_, strides=(1,1), padding=\"same\")(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = ELU()(layer)\n",
    "\n",
    "    layer = SeparableConv2D(in_, kernel_size=k_, strides=strides, padding=\"same\")(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = ELU()(layer)\n",
    "\n",
    "    layer = SeparableConv2D(out_, kernel_size = k_, strides=(1,1), padding = \"same\")(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "\n",
    "    if strides != (1,1) or useShortcut:\n",
    "        shortcut = SeparableConv2D(out_, kernel_size = k_, strides=strides, padding = \"same\")(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    layer = Add()([shortcut, layer])\n",
    "    layer = ReLU()(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def cnn_branch(input_, k_ = (4,4)):\n",
    "\n",
    "    layer = SeparableConv2D(16, kernel_size = k_, strides = (1,1), padding = \"same\")(input_)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = ReLU()(layer)\n",
    "\n",
    "    layer = residual_block(layer, k_, 16, 32, useShortcut = True)\n",
    "    layer = MaxPooling2D()(layer)\n",
    "\n",
    "    layer = residual_block(layer, k_, 32, 64, useShortcut = True)\n",
    "    layer = MaxPooling2D()(layer)\n",
    "\n",
    "    layer = residual_block(layer, k_, 64, 128, useShortcut = True)\n",
    "    layer = MaxPooling2D()(layer)\n",
    "\n",
    "    layer = residual_block(layer, k_, 128, 256, useShortcut = True)\n",
    "    layer = MaxPooling2D()(layer)\n",
    "\n",
    "    layer = residual_block(layer, k_, 256, 384, useShortcut = True)\n",
    "    layer = GlobalAveragePooling2D()(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def create_cnn_model(size = (75, 75), k_=(5,5)):\n",
    "    input_ = Input((75,75,1))\n",
    "\n",
    "    branch_1 = cnn_branch(input_, k_)\n",
    "    branch_2 = cnn_branch(input_, k_)\n",
    "\n",
    "    layer = Concatenate()([branch_1, branch_2])\n",
    "\n",
    "    layer = Dense(512, activation = \"relu\")(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(256, activation = \"relu\")(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(128, activation = \"relu\")(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(64, activation = \"relu\")(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(2, activation = \"softmax\")(layer)\n",
    "\n",
    "    model = Model(inputs = input_, outputs = layer)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:23:54.192712Z",
     "end_time": "2024-04-24T22:23:54.211712Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "class MaxAccuracy(Callback):\n",
    "    def __init__(self):\n",
    "        super(MaxAccuracy, self).__init__()\n",
    "        self.max_train_accuracy = 0.0\n",
    "        self.max_val_accuracy = 0.0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_accuracy = logs['accuracy']\n",
    "        val_accuracy = logs['val_accuracy']\n",
    "        if train_accuracy > self.max_train_accuracy:\n",
    "            self.max_train_accuracy = train_accuracy\n",
    "        if val_accuracy > self.max_val_accuracy:\n",
    "            self.max_val_accuracy = val_accuracy\n",
    "        print(\n",
    "            f\" Max Train Accuracy: {self.max_train_accuracy:.4f}, Max Validation Accuracy: {self.max_val_accuracy:.4f}\")\n",
    "\n",
    "def train_model(model, model_loc, x, y, n_splits=1, test_size=0.25, random_state=47, n_epochs=30,\n",
    "                min_learning_rate=0.0000001, lr_decay_factor=0.8):\n",
    "    splitter = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    aug_set_id = 0\n",
    "    histories = []\n",
    "    max_accuracy = MaxAccuracy()\n",
    "    for train_ids, test_ids in splitter.split(x, y):\n",
    "        checkpoint = ModelCheckpoint(\"model_\" + str(model_loc) + \"_\" + str(aug_set_id) + \".h5\", monitor=\"val_accuracy\",\n",
    "                                     save_best_only=True, model=\"max\")\n",
    "        aug_set_id = aug_set_id + 1\n",
    "\n",
    "        x_train, x_test, y_train, y_test = x[train_ids], x[test_ids], y[train_ids], y[test_ids]\n",
    "\n",
    "        histories.append(model.fit(x_train, y_train, batch_size=32,\n",
    "                                   epochs=n_epochs, validation_data=(x_test, y_test),\n",
    "                                   callbacks=[ReduceLROnPlateau(monitor=\"val_accuracy\", factor=lr_decay_factor,\n",
    "                                                                patience=2, min_lr=min_learning_rate), checkpoint, max_accuracy]))\n",
    "\n",
    "    return histories"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:24:02.846792Z",
     "end_time": "2024-04-24T22:24:02.935926Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images, labels = load_data(\".\", (600, 600))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:24:04.466909Z",
     "end_time": "2024-04-24T22:24:55.037798Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#images[2099].reshape(600,600)\n",
    "im_to_save = (images[2099]*255).reshape(600,600).astype(np.uint8)\n",
    "img = Image.fromarray(im_to_save)\n",
    "img.save(\"file.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-21T21:38:05.656900Z",
     "end_time": "2024-04-21T21:38:05.718938Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "labels = to_categorical(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T21:10:56.141863Z",
     "end_time": "2024-04-24T21:10:56.155862Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "from keras.utils import plot_model\n",
    "clear_session()\n",
    "n_splits = 8\n",
    "res = 600\n",
    "factor = int(res/n_splits)\n",
    "n_model = 0\n",
    "histories = {}\n",
    "for i in range(n_splits):\n",
    "    for j in range(n_splits):\n",
    "        model = create_cnn_model()\n",
    "        plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "        model.compile(optimizer=RMSprop(), metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
    "        histories[n_model] = train_model(model, n_model, images[:, i*factor:min((i+1)*factor, res), j*factor:min((j+1)*factor, res), :], labels)\n",
    "        n_model = n_model+1\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-20T00:23:14.321813Z",
     "end_time": "2024-03-22T03:55:54.577529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('base_histories.pkl', 'wb') as f:\n",
    "    pickle.dump(histories, f)\n",
    "#with open('!!saved_scores\\histories.pkl', 'rb') as f:\n",
    "#    histories_saved = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:12:48.442788Z",
     "end_time": "2024-04-24T22:12:48.713378Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('base_histories.pkl', 'rb') as f:\n",
    "    base_histories_saved = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('!!saved_scores\\histories.pkl', 'rb') as f:\n",
    "    histories_saved = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(histories[0][0].history['loss'], color=\"orange\", label=\"PatchCNN w/o residual learning\")\n",
    "plt.plot(histories_saved[0][0].history['loss'], color=\"blue\", label=\"PatchCNN w residual learning\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.gcf().set_dpi(300)\n",
    "plt.savefig('plot.png', bbox_inches='tight', pad_inches=0, dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:18:55.863597Z",
     "end_time": "2024-04-24T22:18:56.170597Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "histories_saved[0][0].history['loss']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:14:25.029403Z",
     "end_time": "2024-04-24T22:14:25.046400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_accs = {}\n",
    "model = create_cnn_model()\n",
    "model.compile(optimizer=RMSprop(), metrics=[\"accuracy\"], loss=\"binary_crossentropy\")\n",
    "for n_model in range(64):\n",
    "    n_splits = 8\n",
    "    res = 600\n",
    "    factor = int(res/n_splits)\n",
    "    best_split = 0\n",
    "    for n_split in range(1):\n",
    "        model.load_weights(\"model_\"+str(n_model)+\"_\"+str(n_split)+\".h5\")\n",
    "        eval = model.evaluate(images[:, int(n_model/n_splits)*factor:min((int(n_model/n_splits)+1)*factor, res), int(n_model%n_splits)*factor:min((int(n_model%n_splits)+1)*factor, res), :], labels)\n",
    "        best_split = eval[1] if best_split < eval[1] else best_split\n",
    "        model_accs[n_model] = best_split\n",
    "    print(\"Region \" + str(n_model) + \" : \" + str(best_split))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T01:50:07.067777Z",
     "end_time": "2024-04-12T02:17:56.735103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models={}\n",
    "from keras.models import load_model\n",
    "for n_model in model_accs:\n",
    "    if model_accs[n_model] > 0.97:\n",
    "        model = load_model(\"model_\"+str(n_model)+\"_0.h5\")\n",
    "        models[n_model]=model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T02:51:36.262251Z",
     "end_time": "2024-04-12T02:52:10.814088Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"best_model.json\", \"w\") as file:\n",
    "    json.dump(list(models.keys()), file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T03:04:38.206654Z",
     "end_time": "2024-04-12T03:04:38.217653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"best_model.json\", \"r\") as file:\n",
    "    model_list = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:29:28.228359Z",
     "end_time": "2024-04-24T22:29:28.240419Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "from keras.models import load_model\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "sub_models = []\n",
    "sub_model_outputs = []\n",
    "n_splits = 8\n",
    "res = 600\n",
    "factor = int(res/n_splits)\n",
    "main_input = Input((600, 600, 1))\n",
    "def extract_patch(input_image, n_model, size=factor):\n",
    "    return input_image[:, int(n_model/n_splits)*factor:min((int(n_model/n_splits)+1)*factor, res), int(n_model%n_splits)*factor:min((int(n_model%n_splits)+1)*factor, res), :]\n",
    "\n",
    "for n_model in model_list:\n",
    "    model = load_model(\"!!saved_scores\\model_\"+str(n_model)+\"_0.h5\")\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "    new_output_layer = Dense(1, activation=\"sigmoid\")(model.layers[-2].output)\n",
    "    sub_model = Model(inputs = model.input, outputs = new_output_layer)\n",
    "    start_row, start_col = (n_model // n_splits) * 60, (n_model % n_splits) * 60  # Adjust based on your actual layout\n",
    "    patch = Lambda(extract_patch, arguments={'n_model': n_model})(main_input)\n",
    "\n",
    "    sub_models.append(sub_model)\n",
    "    sub_model_outputs.append(sub_model(patch))\n",
    "concatenated_outputs = Concatenate()(sub_model_outputs)\n",
    "dense_layer = Dense(64, activation='relu')(concatenated_outputs)\n",
    "final_output = Dense(2, activation='softmax')(dense_layer)\n",
    "ensemble_model = Model(inputs=main_input, outputs=final_output)\n",
    "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "ensemble_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:29:29.257924Z",
     "end_time": "2024-04-24T22:30:14.425721Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "histories = train_model(ensemble_model, \"universal\", images, labels)\n",
    "#ensemble_model.load_weights(\"model_universal_0.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:37:27.364196Z",
     "end_time": "2024-04-24T22:37:31.449015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "predictions = ensemble_model.predict(images)\n",
    "preds = np.argmax(predictions, axis=1)\n",
    "pred_probs = predictions[:,1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T22:35:55.287924Z",
     "end_time": "2024-04-24T22:35:55.301925Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, _ = roc_curve(labels, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.savefig('roc.png', bbox_inches='tight', pad_inches=0, dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T23:23:46.802160Z",
     "end_time": "2024-04-24T23:23:47.033529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "precision, recall, _ = precision_recall_curve(labels, pred_probs)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='darkorange', lw=2)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "plt.savefig('prerec.png', bbox_inches='tight', pad_inches=0, dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T23:30:41.860839Z",
     "end_time": "2024-04-24T23:30:42.055846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confCXR.png', bbox_inches='tight', pad_inches=0, dpi=300, facecolor='white')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-25T00:02:37.889358Z",
     "end_time": "2024-04-25T00:02:38.059359Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('histories_ensemble.pkl', 'wb') as f:\n",
    "    pickle.dump(histories, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Grad-CAM for patch CNNs\n",
    "#Needs modification after multi branch approach\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "n_model = 8\n",
    "n_splits = 8\n",
    "res = 600\n",
    "factor = int(res/n_splits)\n",
    "bestModel = keras.models.load_model(\"!!saved_scores\\model_8_0.h5\")\n",
    "image = images[400]\n",
    "image = image[int(n_model/n_splits)*factor:min((int(n_model/n_splits)+1)*factor, res), int(n_model%n_splits)*factor:min((int(n_model%n_splits)+1)*factor, res)]\n",
    "target_layers = []\n",
    "sub_models = []\n",
    "target_layers.append(bestModel.get_layer(index=-23))\n",
    "target_layers.append(bestModel.get_layer(index=-24))\n",
    "sub_models.append(tf.keras.models.Model(bestModel.inputs, [target_layers[0].output, bestModel.output]))\n",
    "sub_models.append(tf.keras.models.Model(bestModel.inputs, [target_layers[1].output, bestModel.output]))\n",
    "\n",
    "target_class = []\n",
    "preds = []\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    last_conv_out_1, preds_1 = sub_models[0](image)\n",
    "    last_conv_out_2, preds_2 = sub_models[1](image)\n",
    "    tape.watch(last_conv_out_1)\n",
    "    tape.watch(last_conv_out_2)\n",
    "    target_class.append(preds_1[0][0])\n",
    "    target_class.append(preds_2[0][0])\n",
    "\n",
    "grads=[]\n",
    "pooled_grads = []\n",
    "grads.append(tape.gradient(target_class[0], last_conv_out_1))\n",
    "grads.append(tape.gradient(target_class[1], last_conv_out_2))\n",
    "pooled_grads.append(tf.reduce_mean(grads[0], axis=(0, 1, 2)))\n",
    "pooled_grads.append(tf.reduce_mean(grads[1], axis=(0, 1, 2)))\n",
    "\n",
    "last_conv_out_1 = last_conv_out_1[0]\n",
    "last_conv_out_2 = last_conv_out_2[0]\n",
    "\n",
    "heatmap = last_conv_out_1 @ pooled_grads[0][..., tf.newaxis]\n",
    "heatmap = tf.squeeze(heatmap)\n",
    "heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "\n",
    "plt.imshow(heatmap)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-14T09:30:58.152551Z",
     "end_time": "2024-02-14T09:30:59.513549Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
